# python-services/docker-compose.yml
version: '3.8'

services:
  # Vector Database for RAG
  qdrant:
    image: qdrant/qdrant:latest
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant_storage:/qdrant/storage
    environment:
      - QDRANT__SERVICE__GRPC_PORT=6334
    restart: unless-stopped

  extractor:
    build: ./extractor
    ports:
      - "8000:8000"
    environment:
      - LOG_LEVEL=info
    volumes:
      - ./extractor:/app
    restart: unless-stopped

  classifier:
    build: ./classifier
    ports:
      - "8001:8001"
    environment:
      - GEMINI_API_KEY=${GEMINI_API_KEY:-AIzaSyBkuu6HZHTrMqtni0rsqepjhyyppu5Oh1U}
      - LOG_LEVEL=info
    dns:
      - 8.8.8.8
      - 8.8.4.4
      - 1.1.1.1
    volumes:
      - ./classifier:/app
    restart: unless-stopped

  chat:
    build: ./chat
    ports:
      - "8002:8002"
    environment:
      - GEMINI_API_KEY=${GEMINI_API_KEY:-AIzaSyBkuu6HZHTrMqtni0rsqepjhyyppu5Oh1U}
      - RAG_SERVICE_URL=http://rag:8004
      - LOG_LEVEL=info
    volumes:
      - ./chat:/app
    depends_on:
      - rag
    restart: unless-stopped

  transcriber:
    build: ./transcriber
    ports:
      - "8003:8003"
    environment:
      - ASR_MODELS_DIR=/app/models
      - VOSK_MODEL_SUBPATH=vosk-model-small-en-us-0.15
      - LOG_LEVEL=info
    volumes:
      - ./transcriber:/app
      - ./asr_models:/app/models
    restart: unless-stopped

  # Multi-tenant RAG Service
  rag:
    build: ./rag
    ports:
      - "8004:8004"
    environment:
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6333
      - SUPABASE_URL=${SUPABASE_URL:-http://host.docker.internal:54321}
      - SUPABASE_SERVICE_KEY=${SUPABASE_SERVICE_KEY}
      - LOG_LEVEL=info
    volumes:
      - ./rag:/app
    depends_on:
      - qdrant
    restart: unless-stopped

  # Vision Language Model (LVM) Service
  lvm:
    build: ./lvm
    ports:
      - "8005:8005"
    environment:
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY}
      - SITE_URL=https://smartclaim.ai
      - SITE_NAME=SmartClaim AI
      - LVM_PORT=8005
      - LVM_TIMEOUT=60
      - LOG_LEVEL=info
    dns:
      - 8.8.8.8
      - 8.8.4.4
      - 1.1.1.1
    volumes:
      - ./lvm:/app
    restart: unless-stopped

  # Multimodal Evidence Aggregator Service
  aggregator:
    build: ./aggregator
    ports:
      - "8006:8006"
    environment:
      - CLASSIFIER_URL=http://classifier:8001
      - LVM_URL=http://lvm:8005
      - LOG_LEVEL=info
    volumes:
      - ./aggregator:/app
    depends_on:
      - classifier
      - lvm
    restart: unless-stopped

  # Predictive SLA Service
  sla:
    build: ./sla
    ports:
      - "8007:8007"
    environment:
      - SLA_MODEL_PATH=/app/models/sla_model.pkl
      - LOG_LEVEL=info
    volumes:
      - ./sla:/app
    restart: unless-stopped

volumes:
  qdrant_storage: